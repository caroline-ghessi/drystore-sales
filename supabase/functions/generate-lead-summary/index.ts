import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.56.0';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

const supabase = createClient(
  Deno.env.get('SUPABASE_URL') ?? '',
  Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
);

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { conversationId } = await req.json();

    if (!conversationId) {
      return new Response(
        JSON.stringify({ error: 'conversationId √© obrigat√≥rio' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // 1. Buscar dados da conversa
    const { data: conversation, error: convError } = await supabase
      .from('conversations')
      .select('*')
      .eq('id', conversationId)
      .single();

    if (convError || !conversation) {
      return new Response(
        JSON.stringify({ error: 'Conversa n√£o encontrada' }),
        { status: 404, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // 2. Buscar contexto do projeto
    const { data: projectContext } = await supabase
      .from('project_contexts')
      .select('*')
      .eq('conversation_id', conversationId)
      .single();

    // 3. Buscar contextos extra√≠dos
    const { data: extractedContexts } = await supabase
      .from('extracted_contexts')
      .select('*')
      .eq('conversation_id', conversationId)
      .eq('is_active', true);

    // 4. Buscar mensagens com m√≠dia
    const { data: messages } = await supabase
      .from('messages')
      .select('*')
      .eq('conversation_id', conversationId)
      .order('created_at', { ascending: true });

    // 5. Identificar arquivos de m√≠dia
    const mediaFiles = messages?.filter(msg => msg.media_url && msg.media_type) || [];
    const mediaLinks = mediaFiles.map(file => ({
      type: file.media_type,
      url: file.media_url,
      timestamp: file.created_at
    }));

    // 6. Buscar agente de resumos
    const { data: summarizerAgent } = await supabase
      .from('agent_configs')
      .select('*')
      .eq('agent_type', 'summarizer')
      .eq('is_active', true)
      .single();

    if (!summarizerAgent) {
      return new Response(
        JSON.stringify({ error: 'Agente de resumos n√£o encontrado' }),
        { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // 7. Preparar dados para o prompt
    const conversationHistory = messages?.filter(msg => msg.sender_type === 'customer')
      .map(msg => `${msg.sender_name || 'Cliente'}: ${msg.content}`)
      .join('\n') || 'Nenhuma mensagem do cliente';

    const contextData = {
      // Dados b√°sicos
      nome: conversation.customer_name || 'N√£o informado',
      whatsapp: conversation.whatsapp_number || 'N√£o informado',
      email: conversation.customer_email || 'N√£o informado',
      cidade: conversation.customer_city || 'N√£o informado',
      estado: conversation.customer_state || 'N√£o informado',
      
      // Classifica√ß√£o
      produto_grupo: conversation.product_group || 'N√£o classificado',
      temperatura: conversation.lead_temperature || 'N√£o avaliado',
      score: conversation.lead_score || 0,
      
      // Contexto do projeto
      urgencia: projectContext?.urgency || 'N√£o informado',
      orcamento: projectContext?.budget_range || 'N√£o informado',
      timeline: projectContext?.timeline || 'N√£o informado',
      necessidades: projectContext?.desired_product || 'N√£o informado',
      
      // Hist√≥rico e arquivos
      principais_pontos_discutidos: conversationHistory,
      links_para_arquivos: mediaLinks.length > 0 
        ? mediaLinks.map(link => `${link.type}: ${link.url}`).join('\n')
        : 'Nenhum arquivo enviado'
    };

    // 8. Gerar resumo usando LLM
    const promptWithData = summarizerAgent.system_prompt.replace(
      /\{(\w+)\}/g,
      (match, key) => contextData[key as keyof typeof contextData]?.toString() || match
    );

    // Preparar dados contextuais adicionais
    const additionalContext = [
      `Dados extra√≠dos: ${JSON.stringify(extractedContexts || [])}`,
      `Total de mensagens: ${messages?.length || 0}`,
      `Arquivos enviados: ${mediaFiles.length}`,
      `Contexto do projeto: ${JSON.stringify(projectContext || {})}`
    ].join('\n');

    const llmPrompt = `${promptWithData}\n\nCONTEXTO ADICIONAL:\n${additionalContext}\n\nGere um resumo completo e estruturado baseado nos dados acima.`;

    // 9. Gerar resumo usando LLM com sistema robusto de fallback
    const modelName = summarizerAgent.llm_model || 'gpt-4o-mini';
    
    console.log('ü§ñ INICIANDO GERA√á√ÉO DE RESUMO:', {
      conversationId,
      modelName,
      maxTokens: summarizerAgent.max_tokens,
      temperature: summarizerAgent.temperature,
      promptLength: llmPrompt.length
    });
    
    let llmResponse;
    let llmData;
    let summary = 'Erro ao gerar resumo';
    let attemptedApis = [];
    
    // Fun√ß√£o para tentar Claude API
    const tryClaudeApi = async () => {
      const anthropicApiKey = Deno.env.get('ANTHROPIC_API_KEY');
      if (!anthropicApiKey) {
        throw new Error('Anthropic API key n√£o configurada');
      }
      
      console.log('üîÆ Tentando Claude API com modelo:', modelName);
      attemptedApis.push('claude');
      
      const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
          'x-api-key': anthropicApiKey,
          'anthropic-version': '2023-06-01',
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: modelName,
          max_tokens: summarizerAgent.max_tokens || 2000,
          temperature: summarizerAgent.temperature || 0.3,
          messages: [{ role: 'user', content: llmPrompt }],
        }),
      });
      
      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå Claude API Error:', {
          status: response.status,
          statusText: response.statusText,
          errorText
        });
        throw new Error(`Claude API Error: ${response.status} - ${errorText}`);
      }
      
      const data = await response.json();
      console.log('‚úÖ Claude API Response:', {
        hasContent: !!data.content,
        contentLength: data.content?.[0]?.text?.length || 0,
        usage: data.usage
      });
      
      return data.content?.[0]?.text || null;
    };
    
    // Fun√ß√£o para tentar OpenAI API
    const tryOpenAiApi = async () => {
      const openaiApiKey = Deno.env.get('OPENAI_API_KEY');
      if (!openaiApiKey) {
        throw new Error('OpenAI API key n√£o configurada');
      }
      
      console.log('üß† Tentando OpenAI API como fallback');
      attemptedApis.push('openai');
      
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${openaiApiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            { role: 'system', content: llmPrompt },
            { role: 'user', content: 'Gere o resumo baseado nos dados fornecidos.' }
          ],
          max_tokens: 2000,
          temperature: 0.3,
        }),
      });
      
      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå OpenAI API Error:', {
          status: response.status,
          statusText: response.statusText,
          errorText
        });
        throw new Error(`OpenAI API Error: ${response.status} - ${errorText}`);
      }
      
      const data = await response.json();
      console.log('‚úÖ OpenAI API Response:', {
        hasChoices: !!data.choices,
        contentLength: data.choices?.[0]?.message?.content?.length || 0,
        usage: data.usage
      });
      
      return data.choices?.[0]?.message?.content || null;
    };
    
    // Fun√ß√£o para tentar xAI API
    const tryXaiApi = async () => {
      const xaiApiKey = Deno.env.get('XAI_API_KEY');
      if (!xaiApiKey) {
        throw new Error('xAI API key n√£o configurada');
      }
      
      console.log('üöÄ Tentando xAI API como √∫ltimo recurso');
      attemptedApis.push('xai');
      
      const response = await fetch('https://api.x.ai/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${xaiApiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'grok-beta',
          messages: [
            { role: 'system', content: llmPrompt },
            { role: 'user', content: 'Gere o resumo baseado nos dados fornecidos.' }
          ],
          max_tokens: 2000,
          temperature: 0.3,
        }),
      });
      
      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå xAI API Error:', {
          status: response.status,
          statusText: response.statusText,
          errorText
        });
        throw new Error(`xAI API Error: ${response.status} - ${errorText}`);
      }
      
      const data = await response.json();
      console.log('‚úÖ xAI API Response:', {
        hasChoices: !!data.choices,
        contentLength: data.choices?.[0]?.message?.content?.length || 0,
        usage: data.usage
      });
      
      return data.choices?.[0]?.message?.content || null;
    };
    
    // Sistema robusto de fallback
    try {
      // 1. Tentar a API configurada primeiro
      if (modelName.startsWith('claude')) {
        try {
          summary = await tryClaudeApi();
        } catch (error) {
          console.warn('‚ö†Ô∏è Claude falhou, tentando OpenAI:', error.message);
          summary = await tryOpenAiApi();
        }
      } else if (modelName.startsWith('grok')) {
        try {
          summary = await tryXaiApi();
        } catch (error) {
          console.warn('‚ö†Ô∏è xAI falhou, tentando OpenAI:', error.message);
          summary = await tryOpenAiApi();
        }
      } else {
        // OpenAI como primeiro
        try {
          summary = await tryOpenAiApi();
        } catch (error) {
          console.warn('‚ö†Ô∏è OpenAI falhou, tentando Claude:', error.message);
          summary = await tryClaudeApi();
        }
      }
      
      // Valida√ß√£o final da resposta
      if (!summary || summary.trim().length < 50) {
        throw new Error('Resposta muito curta ou vazia');
      }
      
      console.log('üéâ RESUMO GERADO COM SUCESSO:', {
        length: summary.length,
        apiUsadas: attemptedApis,
        timestamp: new Date().toISOString()
      });
      
    } catch (error) {
      console.error('üí• FALHA TOTAL EM TODAS AS APIs:', {
        error: error.message,
        attemptedApis,
        conversationId
      });
      
      // Fallback final - usar um template estruturado
      summary = `‚ùå Erro na gera√ß√£o autom√°tica do resumo

**DADOS B√ÅSICOS:**
‚Ä¢ Nome: ${contextData.nome}
‚Ä¢ WhatsApp: ${contextData.whatsapp}
‚Ä¢ Produto: ${contextData.produto_grupo}
‚Ä¢ Temperatura: ${contextData.temperatura}

**CONVERSA√á√ÉO:**
${contextData.principais_pontos_discutidos.substring(0, 500)}...

**A√á√ÉO NECESS√ÅRIA:**
Este resumo foi gerado automaticamente devido a falha na IA. 
Revise a conversa completa antes de enviar ao vendedor.

APIs testadas: ${attemptedApis.join(', ')}
Erro: ${error.message}`;
      
      // Log detalhado do erro
      await supabase.from('system_logs').insert({
        level: 'error',
        source: 'generate-lead-summary-api-failure',
        message: 'Falha em todas as APIs de IA',
        data: {
          conversationId,
          attemptedApis,
          error: error.message,
          modelName,
          promptLength: llmPrompt.length
        }
      });
    }

    // 10. Log detalhado da gera√ß√£o
    await supabase.from('system_logs').insert({
      level: 'info',
      source: 'generate-lead-summary',
      message: 'Resumo gerado com sucesso',
      data: {
        conversation_id: conversationId,
        summary_length: summary.length,
        media_files_count: mediaFiles.length,
        model_used: modelName,
        apis_attempted: attemptedApis,
        prompt_length: llmPrompt.length,
        generation_success: true
      }
    });

    console.log('üìä RESUMO COMPLETO GERADO:', {
      conversationId,
      summaryLength: summary.length,
      mediaFilesCount: mediaFiles.length,
      contextDataKeys: Object.keys(contextData),
      success: true
    });

    return new Response(
      JSON.stringify({ 
        success: true,
        summary,
        conversation,
        mediaFiles: mediaLinks,
        contextData,
        metadata: {
          modelUsed: modelName,
          apisAttempted: attemptedApis,
          generatedAt: new Date().toISOString()
        }
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

  } catch (error) {
    console.error('üí• ERRO CR√çTICO NA GERA√á√ÉO DE RESUMO:', {
      conversationId: conversationId || 'n√£o fornecido',
      error: error.message,
      stack: error.stack,
      timestamp: new Date().toISOString()
    });

    await supabase.from('system_logs').insert({
      level: 'error',
      source: 'generate-lead-summary',
      message: 'Erro cr√≠tico na gera√ß√£o de resumo',
      data: { 
        conversation_id: conversationId || null,
        error: error.message,
        stack: error.stack
      }
    });

    return new Response(
      JSON.stringify({ 
        error: `Falha na gera√ß√£o do resumo: ${error.message}`,
        success: false 
      }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );
  }
});